{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:02<00:00, 70.73it/s]\n",
      "100%|██████████| 190/190 [00:01<00:00, 140.87it/s]\n",
      "100%|██████████| 190/190 [00:01<00:00, 112.78it/s]\n",
      "100%|██████████| 196/196 [00:01<00:00, 100.81it/s]\n",
      "100%|██████████| 187/187 [00:01<00:00, 98.73it/s] \n",
      "100%|██████████| 201/201 [00:04<00:00, 48.86it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/Users/ryanklapper/Desktop/2020/Data Science/search-bing-api/dataset/\"\n",
    "\n",
    "CATEGORIES = [\"Bagpipes\",\"Harmonica\",\"Flute\",\"Piano\",\"Saxophone\",\"Guitar\",]\n",
    "training_data = []\n",
    "IMG_SIZE = 350\n",
    "def train():\n",
    "    for category in CATEGORIES:  # iterate each religion\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to different religions\n",
    "        class_num = CATEGORIES.index(category)  # get the classification of each religion\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image in each religion\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "train()\n",
    "\n",
    "# Shuffling data so each religion is trained without bias\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "pictures = []\n",
    "for music_features,music_label in training_data:\n",
    "    X.append(music_features)\n",
    "    y.append(music_label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save_X = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_save_X)\n",
    "pickle_save_X.close()\n",
    "\n",
    "pickle_save_y = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_save_y)\n",
    "pickle_save_y.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-2acae2d951a0>:45: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 114.3 steps\n",
      "Epoch 1/4\n",
      "115/114 [==============================] - 56s 490ms/step - loss: 2.9485 - accuracy: 0.2485\n",
      "Epoch 2/4\n",
      "115/114 [==============================] - 58s 507ms/step - loss: 1.6237 - accuracy: 0.3351\n",
      "Epoch 3/4\n",
      "115/114 [==============================] - 57s 493ms/step - loss: 1.4893 - accuracy: 0.3788\n",
      "Epoch 4/4\n",
      "115/114 [==============================] - 55s 481ms/step - loss: 1.3110 - accuracy: 0.4864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1518e1050>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = \"Is-Music-Relevant-CNN\"\n",
    "\n",
    "pickle_load_X = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_load_X)\n",
    "\n",
    "pickle_load_y = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_load_y)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.14,\n",
    "    height_shift_range=0.14,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(X)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(30, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(30, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(6))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Go through 10 samples at a time\n",
    "# Train 70% , Test 30%\n",
    "# Iterate 3 times (epochs = 3)\n",
    "epochs = 4\n",
    "model.fit_generator(datagen.flow(X, y, batch_size=10),\n",
    "                    steps_per_epoch=len(X) / 10, epochs=epochs,callbacks=[tensorboard])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
