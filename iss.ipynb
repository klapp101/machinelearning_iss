{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 239.77it/s]\n",
      "100%|██████████| 306/306 [00:01<00:00, 185.76it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 1049.76it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 908.40it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 1052.29it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 363.87it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/Users/ryanklapper/Desktop/2020/Data Science/\"\n",
    "\n",
    "CATEGORIES = [\"Buddhism\",\"Christianity\",\"Hinduism\",\"Islam\",\"Judaism\",\"Sikh\",]\n",
    "training_data = []\n",
    "IMG_SIZE = 350\n",
    "def train():\n",
    "    for category in CATEGORIES:  # iterate each religion\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to different religions\n",
    "        class_num = CATEGORIES.index(category)  # get the classification of each religion\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image in each religion\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "train()\n",
    "\n",
    "# Shuffling data so each religion is trained without bias\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for religion_features,religion_label in training_data:\n",
    "    X.append(religion_features)\n",
    "    y.append(religion_label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save_X = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_save_X)\n",
    "pickle_save_X.close()\n",
    "\n",
    "pickle_save_y = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_save_y)\n",
    "pickle_save_y.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1260 samples, validate on 540 samples\n",
      "Epoch 1/3\n",
      "1260/1260 [==============================] - 44s 35ms/sample - loss: 1.1518 - accuracy: 0.5675 - val_loss: 0.3279 - val_accuracy: 0.9296\n",
      "Epoch 2/3\n",
      "1260/1260 [==============================] - 42s 33ms/sample - loss: 0.1623 - accuracy: 0.9643 - val_loss: 0.1052 - val_accuracy: 0.9685\n",
      "Epoch 3/3\n",
      "1260/1260 [==============================] - 43s 34ms/sample - loss: 0.0588 - accuracy: 0.9817 - val_loss: 0.0716 - val_accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ae937d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_load_X = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_load_X)\n",
    "\n",
    "pickle_load_y = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_load_y)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(20, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(20, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(6))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Go through 10 samples at a time\n",
    "# Train 70% , Test 30%\n",
    "# Iterate 3 times (epochs = 3)\n",
    "\n",
    "model.fit(X, y, batch_size=10, epochs=3, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
