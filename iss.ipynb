{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:02<00:00, 71.44it/s]\n",
      "100%|██████████| 190/190 [00:01<00:00, 137.57it/s]\n",
      "100%|██████████| 190/190 [00:01<00:00, 117.13it/s]\n",
      "100%|██████████| 196/196 [00:01<00:00, 101.00it/s]\n",
      "100%|██████████| 187/187 [00:01<00:00, 95.77it/s]\n",
      "100%|██████████| 201/201 [00:04<00:00, 48.43it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/Users/ryanklapper/Desktop/2020/Data Science/search-bing-api/dataset/\"\n",
    "\n",
    "CATEGORIES = [\"Bagpipes\",\"Harmonica\",\"Flute\",\"Piano\",\"Saxophone\",\"Guitar\",]\n",
    "training_data = []\n",
    "IMG_SIZE = 350\n",
    "def train():\n",
    "    for category in CATEGORIES:  # iterate each instrument\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to different instruments\n",
    "        class_num = CATEGORIES.index(category)  # get the classification of each instrument\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image in each instrument\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "train()\n",
    "# Shuffling data so each religion is trained without bias\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for music_features,music_label in training_data:\n",
    "    X.append(music_features)\n",
    "    y.append(music_label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Prepare the training images\n",
    "X_train = X_train.reshape(X_train.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "\n",
    "# # Prepare the test images\n",
    "# X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_test /= 255\n",
    "\n",
    "# Prepare the validation images\n",
    "X_val = X_val.reshape(X_val.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
    "X_val = X_val.astype('float32')\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR_TEST = \"/Users/ryanklapper/Desktop/2020/Data Science/images\"\n",
    "testing_data = []\n",
    "def test():\n",
    "    for img in tqdm(os.listdir(DATADIR_TEST)):\n",
    "        try:\n",
    "            img_test_array = cv2.imread(os.path.join(DATADIR_TEST,img) ,cv2.IMREAD_GRAYSCALE) # convert to array\n",
    "            new_test_array = cv2.resize(img_test_array, (IMG_SIZE, IMG_SIZE)) # resize to normalize data size\n",
    "            testing_data.append([new_test_array])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save_X = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_save_X)\n",
    "pickle_save_X.close()\n",
    "\n",
    "pickle_save_y = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_save_y)\n",
    "pickle_save_y.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 348, 348, 30)      300       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 348, 348, 30)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 174, 174, 30)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 172, 172, 30)      8130      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172, 172, 30)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 86, 86, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 221880)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1331286   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,339,716\n",
      "Trainable params: 1,339,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NAME = \"Is-Music-Relevant-CNN\"\n",
    "\n",
    "pickle_load_X = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_load_X)\n",
    "\n",
    "pickle_load_y = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_load_y)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X, y, batch_size=32)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=32)\n",
    "\n",
    "# datagen.fit(X)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(30, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(30, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(6))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Go through 10 samples at a time\n",
    "# Train 70% , Test 30%\n",
    "# Iterate 3 times (epochs = 3)\n",
    "# epochs = 4\n",
    "# model.fit_generator(datagen.flow(X, y, batch_size=10),\n",
    "#                     steps_per_epoch=len(X) / 10, epochs=epochs,callbacks=[tensorboard])\n",
    "\n",
    "\n",
    "# test_statistics = new_model.evaluate(X, y, verbose=0)\n",
    "# print('Test loss:', test_statistics[0])\n",
    "# print('Test accuracy:', test_statistics[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'fit_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-858e636cb243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m action = model.fit_generator(batches, steps_per_epoch=len(X)//32, epochs=4,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=val_batches, validation_steps=0.3,callbacks=[tensorboard])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_statistics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'fit_generator'"
     ]
    }
   ],
   "source": [
    "action = model.fit_generator(batches, steps_per_epoch=len(X)//32, epochs=4,\n",
    "                    validation_data=val_batches, validation_steps=0.3,callbacks=[tensorboard])\n",
    "\n",
    "test_statistics = action.evaluate(X, y, verbose=0)\n",
    "print('Test loss:', test_statistics[0])\n",
    "print('Test accuracy:', test_statistics[1])\n",
    "%matplotlib inline\n",
    "\n",
    "accuracy = action.history['accuracy']\n",
    "val_accuracy = action.history['val_accuracy']\n",
    "loss = action.history['loss']\n",
    "val_loss = action.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
